{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import idx2numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_X = idx2numpy.convert_from_file('Data/MNIST/train-images.idx3-ubyte')\n",
    "y = idx2numpy.convert_from_file('Data/MNIST/train-labels.idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for digit in range(10):\n",
    "    samples = orig_X[y == digit]\n",
    "    random_samples = np.random.choice(range(0, len(samples)), 1) # MAKE IT 5 !TODO\n",
    "    for i in random_samples:\n",
    "        plt.imshow(samples[i])\n",
    "        plt.title(f'digit {digit}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X, y, folds=5, shuffle=True):\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    n = X.shape[0]\n",
    "    if shuffle:\n",
    "        p = np.random.permutation(n)\n",
    "        X, y = X[p], y[p]\n",
    "    num = n // folds\n",
    "    left = n % folds\n",
    "    X_folds = []\n",
    "    y_folds = []\n",
    "    prev = 0\n",
    "    for i in range(folds):\n",
    "        length = num + (left > 0)\n",
    "        X_ = np.copy(X[prev: prev + length])\n",
    "        y_ = np.copy(y[prev: prev + length])\n",
    "        X_folds.append(X_)\n",
    "        y_folds.append(y_)\n",
    "        prev += length\n",
    "        left -= 1\n",
    "    return X_folds, y_folds\n",
    "\n",
    "def form_train_val(X_folds, y_folds, val_fold):\n",
    "    train_X_folds = [X_folds[i] for i in range(len(X_folds)) if i != val_fold]\n",
    "    train_y_folds = [y_folds[i] for i in range(len(y_folds)) if i != val_fold]\n",
    "    train_X = np.concatenate(train_X_folds, axis=0)\n",
    "    train_y = np.concatenate(train_y_folds, axis=0)\n",
    "    val_X = np.copy(X_folds[val_fold])\n",
    "    val_y = np.copy(y_folds[val_fold])\n",
    "    return train_X, train_y, val_X, val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([np.ravel(r) for r in orig_X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_folds, y_folds = split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-6\n",
    "\n",
    "def BCE(y_actual, y_pred):\n",
    "    return -np.mean(y_actual * np.log(y_pred) + (1 - y_actual) * np.log(1 - y_pred))\n",
    "    \n",
    "def accuracy(y_actual, y_pred):\n",
    "    return sum([y_pred[i] == y_actual[i] for i in range(len(y_actual))]) / len(y_actual)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def mode(l):\n",
    "    d = {0: 0}\n",
    "    mode_ = 0\n",
    "    for x in l:\n",
    "        d[x] = (d[x] + 1) if (x in d) else 1\n",
    "        if d[x] > d[mode_]:\n",
    "            mode_ = x\n",
    "    return mode_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegression_Base:\n",
    "    \"\"\"\n",
    "    Logistic Regression Base Class with L2 Regularisation\n",
    "    Utilises Binary Cross Entropy loss as loss criterion\n",
    "    Uses Batch Gradient Descent for updates\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, normalise=True, lr=0.01, reg_lambda=0.01):\n",
    "        self.normalise = normalise\n",
    "        self.lr = lr\n",
    "        self.reg_lambda = reg_lambda\n",
    "\n",
    "    def fit(self, _X, y, _X_val=None, y_val=None, epochs=1000, precision=1e-6, display=False):\n",
    "        if self.normalise:\n",
    "            self.mean = np.mean(_X, axis=0)\n",
    "            self.std = np.std(_X, axis=0) + epsilon\n",
    "            _X = (_X - self.mean) / self.std\n",
    "        X = np.c_[_X, np.ones(_X.shape[0])]\n",
    "        \n",
    "        validation = _X_val is not None\n",
    "        X_val = None\n",
    "        if validation:\n",
    "            if self.normalise:\n",
    "                _X_val = (_X_val - self.mean) / self.std\n",
    "            X_val = np.c_[_X_val, np.ones(_X_val.shape[0])]\n",
    "\n",
    "        self.num_samples, self.dim = X.shape\n",
    "\n",
    "        self.w = np.zeros(self.dim)\n",
    "        self.train_losses = []\n",
    "        self.train_accuracies = []\n",
    "        if validation:\n",
    "            self.validation_losses = []\n",
    "            self.validation_accuracies = []\n",
    "        iters = 0\n",
    "        prev_step_size = np.inf\n",
    "\n",
    "        while iters < epochs and prev_step_size > precision:\n",
    "            self.train_losses.append(self.loss(y, self.prob(X)))\n",
    "            self.train_accuracies.append(accuracy(y, self.predict(_X)))\n",
    "            if validation:\n",
    "                self.validation_losses.append(self.loss(y_val, self.prob(X_val)))\n",
    "                self.validation_accuracies.append(accuracy(y_val, self.predict(_X_val)))\n",
    "\n",
    "            if display:\n",
    "                print(f'Epoch {iters + 1} ----')\n",
    "                print(f'Training loss: {self.train_losses[-1]}')\n",
    "                print(f'Training accuracy: {self.train_accuracies[-1]}')\n",
    "                if validation:\n",
    "                    print(f'Validation loss: {self.validation_losses[-1]}')\n",
    "                    print(f'Validation accuracy: {self.validation_accuracies[-1]}')\n",
    "\n",
    "            w_ = self.w - self.lr * self.grad(X, y)\n",
    "            prev_step_size = np.sum((self.w - w_) ** 2)\n",
    "            self.w = w_\n",
    "            iters += 1\n",
    "        \n",
    "        self.epochs_run = iters\n",
    "\n",
    "    def loss(self, y_actual, y_pred):\n",
    "        return BCE(y_actual, y_pred) + self.reg_lambda * np.sum(self.w ** 2)\n",
    "\n",
    "    def prob(self, X):\n",
    "        return sigmoid(X @ self.w)    \n",
    "\n",
    "    def grad(self, X, y_actual):\n",
    "        y_pred = self.prob(X)\n",
    "        gradient = ((y_pred - y_actual) @ X) / self.num_samples + 2 * self.reg_lambda * self.w\n",
    "        return gradient\n",
    "\n",
    "    def predict(self, _X_test):\n",
    "        if self.normalise:\n",
    "            _X_test = (_X_test - self.mean) / self.std\n",
    "        X_test = np.c_[_X_test, np.ones(_X_test.shape[0])]\n",
    "        y_pred = np.array([int((self.w.T @ x) >= 0) for x in X_test])\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegression:\n",
    "    \"\"\"\n",
    "    Logistic regression class capable of handling muli class classification\n",
    "    Uses LogRegression_Base as base class for logistic regression\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, method, num_classes):\n",
    "        self.method = method\n",
    "        assert (self.method in ['Single', 'OVO', 'OVR'])\n",
    "        self.num_classes = num_classes\n",
    "        if self.num_classes == 2:\n",
    "            self.method = 'Single'\n",
    "        self.models = {}\n",
    "\n",
    "    def fit_single(self, _X, y, _X_val, y_val, epochs):\n",
    "        self.models[0] = LogRegression_Base()\n",
    "        self.models[0].fit(_X, y, _X_val, y_val, epochs)\n",
    "\n",
    "    def fit_ovr(self, _X, y, _X_val, y_val, epochs, display):\n",
    "        if display:\n",
    "            print('* Fitting OVR models')\n",
    "        for c in range(self.num_classes):\n",
    "            y_c = np.array([int(u) for u in (y == c)])\n",
    "            y_val_c = np.array([int(u) for u in (y_val == c)])\n",
    "            self.models[c] = LogRegression_Base()\n",
    "            self.models[c].fit(_X, y_c, _X_val, y_val_c, epochs)\n",
    "            if display:\n",
    "                print(f'> Fitted model {c}')\n",
    "                print(f'> Acc. train: {self.models[c].train_accuracies[-1]}')\n",
    "                if _X_val is not None:\n",
    "                    print(f'> Acc. val: {self.models[c].validation_accuracies[-1]}')\n",
    "                print()\n",
    "        if display:\n",
    "            print('=========')\n",
    "\n",
    "    def fit_ovo(self, _X, y, _X_val, y_val, epochs, display):\n",
    "        if display:\n",
    "            print('* Fitting OVO models')\n",
    "        for c1 in range(self.num_classes):\n",
    "            for c2 in range(c1 + 1, self.num_classes):\n",
    "                idx = (y == c1) | (y == c2)\n",
    "                idx_val = (y_val == c1) | (y_val == c2)\n",
    "                X_c1_c2 = _X[idx]\n",
    "                X_val_c1_c2 = _X_val[idx_val]\n",
    "                y_c1_c2 = np.array([int(u == c1) for u in y[idx]])\n",
    "                y_val_c1_c2 = np.array([int(u == c1) for u in y_val[idx_val]])\n",
    "                self.models[(c1, c2)] = LogRegression_Base()\n",
    "                self.models[(c1, c2)].fit(X_c1_c2, y_c1_c2, X_val_c1_c2, y_val_c1_c2, epochs)\n",
    "                if display:\n",
    "                    print(f'> Fitted model {c1}, {c2}')\n",
    "                    print(f'> Acc. train: {self.models[(c1, c2)].train_accuracies[-1]}')\n",
    "                    if _X_val is not None:\n",
    "                        print(f'> Acc. val: {self.models[(c1, c2)].validation_accuracies[-1]}')\n",
    "                    print()\n",
    "        if display:\n",
    "            print('=========')\n",
    "    \n",
    "    def predict_ovo(self, X):\n",
    "        predictions = {}\n",
    "        for c1 in range(self.num_classes):\n",
    "            for c2 in range(c1 + 1, self.num_classes):\n",
    "                p = self.models[(c1, c2)].predict(X)\n",
    "                predictions[(c1, c2)] = [c1 if u else c2 for u in p]\n",
    "        y_ = np.array(list(predictions.values()))\n",
    "        y = np.array([mode(y_[:, i]) for i in range(X.shape[0])])\n",
    "        return y\n",
    "    \n",
    "    def predict_ovr(self, X):\n",
    "        prob = []\n",
    "        for c in range(self.num_classes):\n",
    "            prob.append(self.models[c].prob(X))\n",
    "        prob_ = np.array(prob)\n",
    "        y = np.array([np.argmax(prob_[:, i]) for i in range(X.shape[0])])\n",
    "        return y\n",
    "        \n",
    "    def fit(self, _X, y, _X_val=None, y_val=None, epochs=500, display=True):\n",
    "        if self.method == 'Single':\n",
    "            self.fit_single(_X, y, _X_val, y_val, epochs)\n",
    "        if self.method == 'OVO':\n",
    "            self.fit_ovo(_X, y, _X_val, y_val, epochs, display)\n",
    "        if self.method == 'OVR':\n",
    "            self.fit_ovr(_X, y, _X_val, y_val, epochs, display)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.method == 'Single':\n",
    "            return self.models[0].predict(X)\n",
    "        if self.method == 'OVO':\n",
    "            return self.predict_ovo(X)\n",
    "        if self.method == 'OVR':\n",
    "            return self.predict_ovr(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovo_df = {'Validation fold': [], 'Train Acc.': [], 'Validation Acc.': []}\n",
    "ovo_models_path = 'Weights/3/ovo-models.sav'\n",
    "ovo_models_exists = os.path.exists(ovo_models_path)\n",
    "ovo_models = joblib.load(ovo_models_path) if ovo_models_exists else []\n",
    "for val_fold in range(len(X_folds)):\n",
    "    t_X, t_y, v_X, v_y = form_train_val(X_folds, y_folds, val_fold)\n",
    "    lr = None\n",
    "    if not ovo_models_exists:\n",
    "        lr = LogRegression(method='OVO', num_classes=10)\n",
    "        lr.fit(t_X, t_y, v_X, v_y)\n",
    "        ovo_models.append(lr)\n",
    "    else:\n",
    "        lr = ovo_models[val_fold]\n",
    "\n",
    "    ovo_df['Validation fold'].append(val_fold)\n",
    "    ovo_df['Train Acc.'].append(accuracy(t_y, lr.predict(t_X)))\n",
    "    ovo_df['Validation Acc.'].append(accuracy(v_y, lr.predict(v_X)))\n",
    "    \n",
    "ovo_df = pd.Dataframe(ovo_df)\n",
    "if not ovo_models_exists:\n",
    "    joblib.dump(ovo_models, ovo_models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr_df = {'Validation fold': [], 'Train Acc.': [], 'Validation Acc.': []}\n",
    "ovr_models_path = 'Weights/3/ovr-models.sav'\n",
    "ovr_models_exists = os.path.exists(ovr_models_path)\n",
    "ovr_models = joblib.load(ovr_models_path) if ovr_models_exists else []\n",
    "for val_fold in range(len(X_folds)):\n",
    "    t_X, t_y, v_X, v_y = form_train_val(X_folds, y_folds, val_fold)\n",
    "    lr = None\n",
    "    if not ovr_models_exists:\n",
    "        lr = LogRegression(method='OVR', num_classes=10)\n",
    "        lr.fit(t_X, t_y, v_X, v_y)\n",
    "        ovr_models.append(lr)\n",
    "    else:\n",
    "        lr = ovr_models[val_fold]\n",
    "\n",
    "    ovr_df['Validation fold'].append(val_fold)\n",
    "    ovr_df['Train Acc.'].append(accuracy(t_y, lr.predict(t_X)))\n",
    "    ovr_df['Validation Acc.'].append(accuracy(v_y, lr.predict(v_X)))\n",
    "    \n",
    "ovr_df = pd.Dataframe(ovr_df)\n",
    "if not ovr_models_exists:\n",
    "    joblib.dump(ovr_models, ovr_models_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
